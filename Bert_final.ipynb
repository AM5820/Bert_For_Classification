{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('names')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import names\n",
        "import csv\n",
        "import random"
      ],
      "metadata": {
        "id": "F_E1W3cwv7on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast"
      ],
      "metadata": {
        "id": "V1y8F5RbYc8C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "EImrq09J1uyG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "id": "yQBGQ0cIYkYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "I1zemG4tYc-9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nltk2wn_tag(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:                    \n",
        "        return None\n",
        "def lemmatize_sentence(sentence):\n",
        "    lem = WordNetLemmatizer()\n",
        "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))    \n",
        "    wn_tagged = map(lambda x: (x[0], nltk2wn_tag(x[1])), nltk_tagged)\n",
        "    res_words = []\n",
        "    for word, tag in wn_tagged:\n",
        "        if tag is None:                        \n",
        "            res_words.append(word)\n",
        "        else:\n",
        "            res_words.append(lem.lemmatize(word, tag))\n",
        "    return \" \".join(res_words)\n",
        "\n",
        "def preprocess_tweet(tweet):\n",
        "    tweet = tweet.lower()\n",
        "    tweet = re.sub(r'http\\S+','',tweet)        # remove urls\n",
        "    tweet = re.sub('[^a-z]',' ',tweet)\n",
        "    tweet = lemmatize_sentence(tweet)\n",
        "\n",
        "    tweet = word_tokenize(tweet)\n",
        "    #add_stop = ['religion','religious']\n",
        "\n",
        "    #tweet = [ps.stem(word) for word in tweet if not word in set(stopwords.words('english'))]\n",
        "    tweet = [word for word in tweet if not word in set(stopwords.words('english'))]\n",
        "    tweet = [word for word in tweet if not word in set(names.words())]\n",
        "\n",
        "    tweet = \" \".join(tweet)\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "OGv34-9mccCg"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Mount drive**"
      ],
      "metadata": {
        "id": "9cDL9SGEtcCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rwyF_6l-saty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_pickle('drive/MyDrive/Bert model/dataset.pickle')\n",
        "dataset.sample(3)"
      ],
      "metadata": {
        "id": "TBoVBrANwCNx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "e69b5392-5af0-4c38-ba55-3d87c166b150"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 content      topic\n",
              "32256  @therealzanetta FULLY explains why I wholehear...  education\n",
              "84543  @Originalmugwug @Artsymarxist @fireyphoenix111...   religion\n",
              "3078   James Corden teases Jennifer Lopez's appearanc...  celebrity"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-533b2b72-1388-4d04-a480-aba7e5fcf835\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32256</th>\n",
              "      <td>@therealzanetta FULLY explains why I wholehear...</td>\n",
              "      <td>education</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84543</th>\n",
              "      <td>@Originalmugwug @Artsymarxist @fireyphoenix111...</td>\n",
              "      <td>religion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3078</th>\n",
              "      <td>James Corden teases Jennifer Lopez's appearanc...</td>\n",
              "      <td>celebrity</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-533b2b72-1388-4d04-a480-aba7e5fcf835')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-533b2b72-1388-4d04-a480-aba7e5fcf835 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-533b2b72-1388-4d04-a480-aba7e5fcf835');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.topic.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgHk7eH1EKzX",
        "outputId": "11c7e3f9-4bda-4ebc-a9b6-e1404bc04b41"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "celebrity    17724\n",
              "education    17724\n",
              "politics     17724\n",
              "religion     17724\n",
              "sports       17703\n",
              "health       17158\n",
              "Name: topic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXk9bub6EWnk",
        "outputId": "7d1782a7-a112-41e3-bf8a-b8df5043485c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105757, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling 1800sample/class = 10800\n",
        "##### train=8640 , val=1080 , test=1080"
      ],
      "metadata": {
        "id": "lYrnPwSrzd55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset.groupby('topic', group_keys=False).apply(lambda x: x.sample(min(len(x), 1800)))"
      ],
      "metadata": {
        "id": "UNIbBOPjuKmE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.topic.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "968uEggEvmtL",
        "outputId": "28f45d64-180f-49dd-a274-9e7e6331ddec"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "celebrity    1800\n",
              "education    1800\n",
              "health       1800\n",
              "politics     1800\n",
              "religion     1800\n",
              "sports       1800\n",
              "Name: topic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test_val,y_train,y_test_val = train_test_split(df.content,df.topic,test_size=0.2,stratify=df.topic)"
      ],
      "metadata": {
        "id": "GKNTlVuSi0Ep"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_val,x_test,y_val,y_test = train_test_split(x_test_val,y_test_val,test_size=0.5,stratify=y_test_val)"
      ],
      "metadata": {
        "id": "g1S8tcCjyWYR"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame(np.column_stack([x_train,y_train]),columns=['content','topic'])"
      ],
      "metadata": {
        "id": "kQ0QX7Pri4gv"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(np.column_stack([x_test,y_test]),columns=['content','topic'])"
      ],
      "metadata": {
        "id": "mg1oXwLUi-bz"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = pd.DataFrame(np.column_stack([x_val,y_val]),columns=['content','topic'])"
      ],
      "metadata": {
        "id": "YeJpOG_qrwKW"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.content = np.vectorize(preprocess_tweet)(train_df.content)\n",
        "val_df.content = np.vectorize(preprocess_tweet)(val_df.content)\n",
        "test_df.content = np.vectorize(preprocess_tweet)(test_df.content)"
      ],
      "metadata": {
        "id": "TlpvlfxghnTM"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Tokenizer"
      ],
      "metadata": {
        "id": "EPUeVgMK0gRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-uncased\"\n",
        "# max sequence length for each document/sentence sample\n",
        "max_length = 512\n",
        "\n",
        "# load the tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)\n",
        "\n",
        "\n",
        "# tokenize the dataset, truncate when passed `max_length`, \n",
        "# and pad with 0's when less than `max_length`\n",
        "train_encodings = tokenizer(train_df.content.to_list(), truncation=True, padding=True, max_length=max_length)\n",
        "valid_encodings = tokenizer(val_df.content.to_list(), truncation=True, padding=True, max_length=max_length)\n",
        "test_encodings = tokenizer(test_df.content.to_list(), truncation=True, padding=True, max_length=max_length)"
      ],
      "metadata": {
        "id": "xH1Ggk7jZWai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode Labels"
      ],
      "metadata": {
        "id": "Ya2iqh96Iyi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "\n",
        "train_labels =  lb.fit_transform(train_df.topic)\n",
        "test_labels =  lb.transform(test_df.topic)\n",
        "val_labels =  lb.transform(val_df.topic)"
      ],
      "metadata": {
        "id": "OeZQnF0sZjrj"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = pd.DataFrame({'encode':train_labels,'true':train_df.topic})"
      ],
      "metadata": {
        "id": "8y7yGMoyXYJd"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = {}\n",
        "for i,k in zip(label_names.encode,label_names.true):\n",
        "  target_names[i] = k"
      ],
      "metadata": {
        "id": "59Az632SX_bW"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNw9HIMzY9f2",
        "outputId": "c833e76b-c756-4f6a-cffb-3e169cb4bbf0"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'celebrity',\n",
              " 1: 'education',\n",
              " 2: 'health',\n",
              " 3: 'politics',\n",
              " 4: 'religion',\n",
              " 5: 'sports'}"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## converting to torch Tensors"
      ],
      "metadata": {
        "id": "HKSU5sb6JEp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsGroupsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# convert our tokenized data into a torch Dataset\n",
        "train_dataset = NewsGroupsDataset(train_encodings, train_labels)\n",
        "valid_dataset = NewsGroupsDataset(valid_encodings, val_labels)\n",
        "test_dataset = NewsGroupsDataset(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "EbeBCMsuZaB2"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Bert Model"
      ],
      "metadata": {
        "id": "K8l2h8jze4a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model and pass to CUDA\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(target_names)).to(\"cuda\")"
      ],
      "metadata": {
        "id": "2Uw2ZYYIZcnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  # calculate accuracy using sklearn's function\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "  }"
      ],
      "metadata": {
        "id": "osyDus4RZoYH"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
        "    warmup_steps=3000,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
        "    logging_steps=400,               # log & save weights each logging_steps\n",
        "    save_steps=400,\n",
        "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
        ")"
      ],
      "metadata": {
        "id": "C9a9QpYoZwGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b24dfaf-c348-45e2-f14b-178ef97ad3bb"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 400\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=valid_dataset,          # evaluation dataset\n",
        "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        ")"
      ],
      "metadata": {
        "id": "SgDrFyvSZxWg"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "bWDu-iULZyqz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b82e20f0-4636-4bbc-c4ff-60037eb533de"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 8640\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3240\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3240' max='3240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3240/3240 20:19, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.385000</td>\n",
              "      <td>0.413007</td>\n",
              "      <td>0.953704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.174200</td>\n",
              "      <td>0.137321</td>\n",
              "      <td>0.974074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.128700</td>\n",
              "      <td>0.138556</td>\n",
              "      <td>0.975000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.099700</td>\n",
              "      <td>0.158591</td>\n",
              "      <td>0.968519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.096200</td>\n",
              "      <td>0.142631</td>\n",
              "      <td>0.970370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.104600</td>\n",
              "      <td>0.117344</td>\n",
              "      <td>0.978704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.079400</td>\n",
              "      <td>0.117540</td>\n",
              "      <td>0.979630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.080500</td>\n",
              "      <td>0.145348</td>\n",
              "      <td>0.978704</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1080\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-400\n",
            "Configuration saved in ./results/checkpoint-400/config.json\n",
            "Model weights saved in ./results/checkpoint-400/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1080\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-800\n",
            "Configuration saved in ./results/checkpoint-800/config.json\n",
            "Model weights saved in ./results/checkpoint-800/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1080\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-1200\n",
            "Configuration saved in ./results/checkpoint-1200/config.json\n",
            "Model weights saved in ./results/checkpoint-1200/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1080\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-1600\n",
            "Configuration saved in ./results/checkpoint-1600/config.json\n",
            "Model weights saved in ./results/checkpoint-1600/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1080\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Configuration saved in ./results/checkpoint-2000/config.json\n",
            "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1080\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-2400\n",
            "Configuration saved in ./results/checkpoint-2400/config.json\n",
            "Model weights saved in ./results/checkpoint-2400/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1080\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-2800\n",
            "Configuration saved in ./results/checkpoint-2800/config.json\n",
            "Model weights saved in ./results/checkpoint-2800/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1080\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-3200\n",
            "Configuration saved in ./results/checkpoint-3200/config.json\n",
            "Model weights saved in ./results/checkpoint-3200/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-2400 (score: 0.1173437088727951).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3240, training_loss=0.2654176871533747, metrics={'train_runtime': 1219.9114, 'train_samples_per_second': 21.247, 'train_steps_per_second': 2.656, 'total_flos': 2903863671452160.0, 'train_loss': 0.2654176871533747, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "B3pJ1zhwqb0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "9veE-auwbMbb",
        "outputId": "d660bdac-e889-42bd-d4fc-2c70e42232fe"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1080\n",
            "  Batch size = 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='108' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 02:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.9842592592592593,\n",
              " 'eval_loss': 0.08592195063829422,\n",
              " 'eval_runtime': 14.1268,\n",
              " 'eval_samples_per_second': 76.451,\n",
              " 'eval_steps_per_second': 3.823}"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving the fine tuned model & tokenizer"
      ],
      "metadata": {
        "id": "oRM7EYTXaka8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"drive/MyDrive/Bert model/bert_model/\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "id": "8UJnz_UagiXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "Ec4-zZtkbG0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(text):\n",
        "    # prepare our text into tokenized sequence\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "    # perform inference to our model\n",
        "    outputs = model(**inputs)\n",
        "    # get output probabilities by doing softmaxs\n",
        "    probs = outputs[0].softmax(1)\n",
        "    # executing argmax function to get the candidate label\n",
        "    return target_names[probs.argmax().item()]"
      ],
      "metadata": {
        "id": "AVZ9UBWyhAoj"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example #1\n",
        "text = \"\"\" johnny depp and his wife amber herd at the court \"\"\"\n",
        "text = preprocess_tweet(text)\n",
        "print(get_prediction(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grUj1kk-hSu5",
        "outputId": "3db18384-42a2-428f-81a4-a46f10d21319"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "celebrity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and testing"
      ],
      "metadata": {
        "id": "wtXqgSdbqpoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tk = BertTokenizerFast.from_pretrained('drive/MyDrive/Bert model/bert_model/',local_files_only=True)\n",
        "bert = BertForSequenceClassification.from_pretrained('drive/MyDrive/Bert model/bert_model/pytorch_model.bin',config='drive/MyDrive/Bert model/bert_model/config.json', local_files_only=True)"
      ],
      "metadata": {
        "id": "xde2hcfCqkXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(text):\n",
        "    # prepare our text into tokenized sequence\n",
        "    inputs = tk(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "    # perform inference to our model\n",
        "    outputs = bert(**inputs)\n",
        "    # get output probabilities by doing softmaxs\n",
        "    probs = outputs[0].softmax(1)\n",
        "    # executing argmax function to get the candidate label\n",
        "    return target_names[probs.argmax().item()]"
      ],
      "metadata": {
        "id": "Iof1YOanuVVd"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example #1\n",
        "text = \"\"\" johnny deep and his ex wife are debating at the court \"\"\"\n",
        "text = preprocess_tweet(text)\n",
        "print(get_prediction(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6kTUcG1uWEr",
        "outputId": "bba5609b-75cb-43e8-d620-bd03110f068d"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "politics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save target_names"
      ],
      "metadata": {
        "id": "f1Qv3oZ1qUxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "eT9qzPKuuYM6"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('drive/MyDrive/Bert model/target_names.pickle','wb') as f:\n",
        "  pickle.dump(target_names,f,protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "yOmWjqVuuWeJ"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X47WrhM5hevr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TyZ-uifQp8Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7AnoGwoDp8JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p9HsbSKTlhgB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}